<!-- <!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>–ì–æ–ª–æ—Å–æ–≤–æ–π –∞–≥–µ–Ω—Ç</title>
  <style>
    body { font-family: sans-serif; padding: 2rem; background: #f2f2f2; }
    button { font-size: 1.2rem; padding: 1rem; margin: 1rem 0; }
  </style>
</head>
<body>
  <h2>üéôÔ∏è –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –∏ –≥–æ–≤–æ—Ä–∏—Ç–µ</h2>
  <button onclick="startRecording()">‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å</button>
  <button onclick="stopRecording()">‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å</button>
  <p><strong>–†–µ—á—å:</strong> <span id="text"></span></p>
  <p><strong>–≠–º–æ—Ü–∏—è:</strong> <span id="emotion"></span> <span id="score"></span></p>

  <script>
    let mediaRecorder;
    let audioChunks = [];

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorder.start();
      audioChunks = [];

      mediaRecorder.ondataavailable = event => {
        audioChunks.push(event.data);
      };
    }

    async function stopRecording() {
        mediaRecorder.stop();
        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const arrayBuffer = await audioBlob.arrayBuffer();

            try {
            const audioBuffer = await decodeAudioData(arrayBuffer);
            const wavBlob = encodeWav(audioBuffer);

            const formData = new FormData();
            formData.append("file", wavBlob, "audio.wav");

            const res = await fetch("/analyze", {
                method: "POST",
                body: formData
            });

            const data = await res.json();

            console.log("üìä DEBUG response:", data);  // <== –í–æ—Ç —ç—Ç–æ –¥–æ–±–∞–≤–∏–º

            document.getElementById("text").innerText = data.text || "‚Äî";
            document.getElementById("emotion").innerText = data.emotion || "‚Äî";
            document.getElementById("score").innerText = data.score ? `(${data.score}%)` : "";
            } catch (err) {
            console.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ/–æ–±—Ä–∞–±–æ—Ç–∫–µ:", err);
            alert("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä–∞. –ü—Ä–æ–≤–µ—Ä—å –∫–æ–Ω—Å–æ–ª—å.");
            }
        };
        }


    async function decodeAudioData(buffer) {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      return await ctx.decodeAudioData(buffer);
    }

    function encodeWav(audioBuffer) {
        const targetSampleRate = 16000;
        const monoData = audioBuffer.getChannelData(0); // —Ç–æ–ª—å–∫–æ 1 –∫–∞–Ω–∞–ª

        // –†–µ—Å—ç–º–ø–ª–∏–Ω–≥: –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
        const ratio = audioBuffer.sampleRate / targetSampleRate;
        const newLength = Math.floor(monoData.length / ratio);
        const resampledData = new Float32Array(newLength);
        for (let i = 0; i < newLength; i++) {
            resampledData[i] = monoData[Math.floor(i * ratio)];
        }

        const buffer = new ArrayBuffer(44 + newLength * 2);
        const view = new DataView(buffer);

        writeUTFBytes(view, 0, 'RIFF');
        view.setUint32(4, 36 + newLength * 2, true);
        writeUTFBytes(view, 8, 'WAVE');
        writeUTFBytes(view, 12, 'fmt ');
        view.setUint32(16, 16, true); // PCM
        view.setUint16(20, 1, true);  // Linear quantization
        view.setUint16(22, 1, true);  // Mono
        view.setUint32(24, targetSampleRate, true);
        view.setUint32(28, targetSampleRate * 2, true); // byte rate
        view.setUint16(32, 2, true); // block align
        view.setUint16(34, 16, true); // bits per sample
        writeUTFBytes(view, 36, 'data');
        view.setUint32(40, newLength * 2, true);

        // PCM samples
        let offset = 44;
        for (let i = 0; i < newLength; i++) {
            const s = Math.max(-1, Math.min(1, resampledData[i]));
            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            offset += 2;
        }

        return new Blob([view], { type: 'audio/wav' });
        }


    function writeUTFBytes(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
  </script>
</body>
</html> -->

<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <title>üéôÔ∏è –ê–≥–µ–Ω—Ç –ø–æ –≥–æ–ª–æ—Å—É</title>
  <style>
    body { font-family: sans-serif; padding: 2rem; background: #f2f2f2; }
    button { font-size: 1.2rem; padding: 1rem 2rem; margin: 1rem 1rem 0 0; cursor: pointer; }
    .result { margin-top: 2rem; }
    .advice { font-size: 1.1rem; margin-top: 1rem; background: #fff9c4; padding: 1rem; border-radius: 8px; }
  </style>
</head>
<body>
  <h2>üß† –ì–æ–ª–æ—Å–æ–≤–æ–π –∞–≥–µ–Ω—Ç –ø—Ä–æ–¥–∞–∂</h2>
  <button id="recordBtn" onclick="toggleRecording()">‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å</button>
  <button onclick="analyze()">üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –∞–Ω–∞–ª–∏–∑</button>

  <div class="result">
    <p><strong>üó£Ô∏è –†–µ—á—å:</strong> <span id="text">‚Äî</span></p>
    <p><strong>üß† –≠–º–æ—Ü–∏—è:</strong> <span id="emotion">‚Äî</span> <span id="score"></span></p>
    <div id="advice" class="advice">üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ—è–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞</div>
  </div>

  <script>
    let isRecording = false;
    let recorder, stream;
    let chunks = [];

    const moodMap = {
      "–†–∞–¥–æ—Å—Ç—å": "‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–π ‚Äî –∫–ª–∏–µ–Ω—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω",
      "–ì—Ä—É—Å—Ç—å": "ü§ù –ü—Ä–æ—è–≤–∏ —ç–º–ø–∞—Ç–∏—é, —É—Ç–æ—á–Ω–∏, –≤ —á—ë–º –ø—Ä–æ–±–ª–µ–º–∞",
      "–ì–Ω–µ–≤": "‚ö†Ô∏è –°–æ—Ö—Ä–∞–Ω–∏ —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ, –≤—ã—Å–ª—É—à–∞–π –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ",
      "–≠–Ω—Ç—É–∑–∏–∞–∑–º": "üöÄ –û—Ç–ª–∏—á–Ω—ã–π –º–æ–º–µ–Ω—Ç –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å–¥–µ–ª–∫–∏",
      "–£–¥–∏–≤–ª–µ–Ω–∏–µ": "üßê –£—Ç–æ—á–Ω–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã–∑–≤–∞–ª–æ —É–¥–∏–≤–ª–µ–Ω–∏–µ",
      "–û—Ç–≤—Ä–∞—â–µ–Ω–∏–µ": "‚ùå –°–º–µ–Ω–∏ –ø–æ–¥—Ö–æ–¥ –∏–ª–∏ —Ç–µ–º—É, –Ω–µ –Ω–∞—Å—Ç–∞–∏–≤–∞–π",
      "–°—Ç—Ä–∞—Ö": "üí¨ –£—Å–ø–æ–∫–æ–π, —É–±–µ—Ä–∏ —Ä–∏—Å–∫–∏, –ø—Ä–µ–¥–ª–æ–∂–∏ –≥–∞—Ä–∞–Ω—Ç–∏—é",
      "–í–∏–Ω–∞": "üîÑ –ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å, –Ω–µ –¥–∞–≤–∏",
      "–°—Ç—ã–¥": "üßò –ë—É–¥—å –º—è–≥–∫–∏–º, –Ω–µ —É—Å–∏–ª–∏–≤–∞–π –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç",
      "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ": "‚ÑπÔ∏è –ó–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å, –∞–∫—Ç–∏–≤–∏—Ä—É–π –∏–Ω—Ç–µ—Ä–µ—Å"
    };

    async function toggleRecording() {
      const btn = document.getElementById("recordBtn");

      if (!isRecording) {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
        recorder.ondataavailable = e => chunks.push(e.data);
        recorder.start();
        btn.textContent = "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å";
        isRecording = true;
      } else {
        recorder.stop();
        stream.getTracks().forEach(t => t.stop());
        btn.textContent = "‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å";
        isRecording = false;
      }
    }

    async function analyze() {
      if (chunks.length === 0) {
        alert("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—à–∏—Ç–µ –≥–æ–ª–æ—Å!");
        return;
      }

      try {
        const blob = new Blob(chunks, { type: 'audio/webm' });
        chunks = []; // –æ—á–∏—Å—Ç–∏—Ç—å –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞

        const arrayBuffer = await blob.arrayBuffer();
        const audioBuffer = await decodeAudioData(arrayBuffer);
        const wavBlob = encodeWav(audioBuffer);

        const formData = new FormData();
        formData.append("file", wavBlob, "audio.wav");

        const res = await fetch("/analyze", {
          method: "POST",
          body: formData
        });

        const data = await res.json();
        document.getElementById("text").innerText = data.text || "‚Äî";
        document.getElementById("emotion").innerText = data.emotion || "‚Äî";
        document.getElementById("score").innerText = data.score ? `(${data.score}%)` : "";
        document.getElementById("advice").innerText = `üí° ${moodMap[data.emotion] || "–ù–µ—Ç —Å–æ–≤–µ—Ç–∞"}`;
      } catch (err) {
        console.error("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞:", err);
        alert("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ. –ü—Ä–æ–≤–µ—Ä—å –∫–æ–Ω—Å–æ–ª—å.");
      }
    }

    async function decodeAudioData(buffer) {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      return await ctx.decodeAudioData(buffer);
    }

    function encodeWav(audioBuffer) {
      const targetSampleRate = 16000;
      const monoData = audioBuffer.getChannelData(0);
      const ratio = audioBuffer.sampleRate / targetSampleRate;
      const newLength = Math.floor(monoData.length / ratio);
      const resampled = new Float32Array(newLength);
      for (let i = 0; i < newLength; i++) resampled[i] = monoData[Math.floor(i * ratio)];

      const buffer = new ArrayBuffer(44 + newLength * 2);
      const view = new DataView(buffer);

      writeUTFBytes(view, 0, 'RIFF');
      view.setUint32(4, 36 + newLength * 2, true);
      writeUTFBytes(view, 8, 'WAVE');
      writeUTFBytes(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, targetSampleRate, true);
      view.setUint32(28, targetSampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeUTFBytes(view, 36, 'data');
      view.setUint32(40, newLength * 2, true);

      let offset = 44;
      for (let i = 0; i < newLength; i++) {
        const s = Math.max(-1, Math.min(1, resampled[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        offset += 2;
      }

      return new Blob([view], { type: 'audio/wav' });
    }

    function writeUTFBytes(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
  </script>
</body>
</html>